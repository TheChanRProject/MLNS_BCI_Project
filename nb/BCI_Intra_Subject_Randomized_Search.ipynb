{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BCI Intra-Subject Randomized Search.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheChanRProject/MLNS_BCI_Project/blob/master/nb/BCI_Intra_Subject_Randomized_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "985VT8rO8pql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc \n",
        "from sklearn.preprocessing import scale \n",
        "from sklearn.neural_network import MLPClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from scipy import interp \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrD-XlKh9Xm4",
        "colab_type": "code",
        "outputId": "715a80a8-8fc0-4a17-a146-5b725b24a16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "!pip install scikit-plot jupyterthemes"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: jupyterthemes in /usr/local/lib/python3.6/dist-packages (0.20.0)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.12.5)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.0.3)\n",
            "Requirement already satisfied: ipython>=5.4.1 in /usr/local/lib/python3.6/dist-packages (from jupyterthemes) (5.5.0)\n",
            "Requirement already satisfied: notebook>=5.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyterthemes) (5.7.8)\n",
            "Requirement already satisfied: lesscpy>=0.11.2 in /usr/local/lib/python3.6/dist-packages (from jupyterthemes) (0.13.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyterthemes) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.9->scikit-plot) (1.16.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.5.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.7.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (41.0.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (1.0.16)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.3.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.2.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (17.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (4.4.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (4.6.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (5.2.4)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (5.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.8.2)\n",
            "Requirement already satisfied: tornado<7,>=4.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (4.5.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (2.10.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.6.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=5.6.0->jupyterthemes) (1.5.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.6/dist-packages (from lesscpy>=0.11.2->jupyterthemes) (3.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from lesscpy>=0.11.2->jupyterthemes) (1.12.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.4.1->jupyterthemes) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.4.1->jupyterthemes) (0.1.7)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (2.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.3)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=5.6.0->jupyterthemes) (1.1.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=5.6.0->jupyterthemes) (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XraYZOsB9dn5",
        "colab_type": "code",
        "outputId": "d2bca4ef-4441-48de-faa1-014c43f29572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  \u001b[0m\u001b[01;34mMLNS_BCI_Project\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y28CGb7a9jBA",
        "colab_type": "code",
        "outputId": "fc298c41-5e64-45c9-9d24-735137b979f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd MLNS_BCI_Project"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/MLNS_BCI_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PTD2KYI9lKm",
        "colab_type": "code",
        "outputId": "d3288a4a-c4fb-4314-b715-123a23a7fcec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/    \u001b[01;34mnb\u001b[0m/              \u001b[01;34mposter\u001b[0m/    \u001b[01;34mresults\u001b[0m/  tasks_resources.md\n",
            "\u001b[01;34mimages\u001b[0m/  \u001b[01;34mpaper-analysis\u001b[0m/  README.md  \u001b[01;34msrc\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAconbjO9mUI",
        "colab_type": "code",
        "outputId": "552d5c5d-8ced-46a1-c802-44e0e470f3fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cd src/cross-val"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'src/cross-val'\n",
            "/content/MLNS_BCI_Project/src/cross-val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOYgkKOw9ouI",
        "colab_type": "code",
        "outputId": "7b1e4628-3256-4a95-9ac2-8d3dfba226d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gridSearch.py                        \u001b[0m\u001b[01;34mtesting\u001b[0m/\n",
            "\u001b[01;34mintra-subject\u001b[0m/                       \u001b[01;34mtraining\u001b[0m/\n",
            "logistic-regression.py               VPaan_DevAttentionX.csv\n",
            "merged_labeled_DevAttentionX_v2.csv  VPaan_DevAttentionY.csv\n",
            "merged_labeled_DevAttentionY_v2.csv  VPaap_DevAttentionX.csv\n",
            "neural-network.py                    VPaap_DevAttentionY.csv\n",
            "\u001b[01;34m__pycache__\u001b[0m/                         VPaas_DevAttentionX.csv\n",
            "random-forest.py                     VPaas_DevAttentionY.csv\n",
            "randomizedSearch.py                  VPgcc_DevAttentionX.csv\n",
            "roc.py                               VPgcc_DevAttentionY.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjpkT5xN9rKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "694adefd-fb2a-4917-eb34-5c5143a8792c"
      },
      "source": [
        "mkdir intra-subject"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘intra-subject’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cYqm5sw9uE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials \n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osIID_cB91Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_x = drive.CreateFile({\"id\": \"1-s6kpsj5Gvc86FtIrfk_AhlRvVZRi8Mj\"}) \n",
        "merged_x.GetContentFile(\"merged_labeled_DevAttentionX.csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whPUXxEl-Ncc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged_y = drive.CreateFile({\"id\": \"1tHrpcAJjUuerjXrDJ1RGNRCmffPtkW33\"})\n",
        "merged_y.GetContentFile(\"merged_labeled_DevAttentionY.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOYbOkki-ZJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv *.csv intra-subject"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwwegmK4-blC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neurFeat = pd.read_csv(\"intra-subject/merged_labeled_DevAttentionX.csv\")\n",
        "neurFeat.drop(list(neurFeat.columns)[0], axis=1, inplace=True)\n",
        "classVals = pd.read_csv(\"intra-subject/merged_labeled_DevAttentionY.csv\")\n",
        "classVals.drop(list(classVals.columns)[0], axis=1, inplace=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8p093zn_BMB",
        "colab_type": "code",
        "outputId": "84b4acd3-6311-4b41-9ff8-ac3171bb3e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(neurFeat.shape)\n",
        "print(classVals.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(126082, 189)\n",
            "(126082, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuYV0BHWAK5W",
        "colab_type": "code",
        "outputId": "57e643a0-3b08-49fd-a1f9-25d873701fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ".20 * 126080"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25216.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R9C_n_xAQYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neuralFeatures = neurFeat.sample(n=126080, axis=0, random_state=100) \n",
        "classValues = classVals.sample(n=126080, axis=0, random_state=100)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVwiQWZAAp-4",
        "colab_type": "code",
        "outputId": "168e33c2-ca3a-4d17-f558-2066d52ab9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(neuralFeatures.shape) \n",
        "print(classValues.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(126080, 189)\n",
            "(126080, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW9sA3x1AuZs",
        "colab_type": "code",
        "outputId": "2561008b-15c0-446a-d142-5b9d0f1eda51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Scale features \n",
        "zFeatures = scale(neuralFeatures, axis=0) \n",
        "\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(zFeatures, classValues, test_size=0.20, random_state=100) \n",
        "\n",
        "print(f\"Shape of X Training Set : {Xtrain.shape}\") \n",
        "print(f\"Shape of X Testing Set : {Xtest.shape}\")\n",
        "print(f\"Shape of Y Training Set: {Ytrain.shape}\")\n",
        "print(f\"Shape of Y Testing Set: {Ytest.shape}\")  "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X Training Set : (100864, 189)\n",
            "Shape of X Testing Set : (25216, 189)\n",
            "Shape of Y Training Set: (100864, 1)\n",
            "Shape of Y Testing Set: (25216, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDNkcyHLB8-k",
        "colab_type": "code",
        "outputId": "1d90a962-26d7-4dab-dac5-08d67bdb3f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gridSearch.py           neural-network.py  randomizedSearch.py  \u001b[0m\u001b[01;34mtraining\u001b[0m/\n",
            "\u001b[01;34mintra-subject\u001b[0m/          \u001b[01;34m__pycache__\u001b[0m/       roc.py\n",
            "logistic-regression.py  random-forest.py   \u001b[01;34mtesting\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxDPHtm5CrnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from randomizedSearch import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7kaX0OZCwsf",
        "colab_type": "code",
        "outputId": "914b37e0-a8ee-4830-e81f-233ca00d8ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        }
      },
      "source": [
        "# Intra Subject Randomized Search \n",
        "\n",
        "rf_rs = RandomForest(Xtrain, Ytrain, cv=5, n=1) \n",
        "print(rf_rs) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 17.2min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   21.7s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 17.1min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   21.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 17.0min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   21.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 16.7min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   21.7s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 16.8min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    4.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   21.8s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'mean_fit_time': array([1018.56565447]), 'std_fit_time': array([10.69879179]), 'mean_score_time': array([4.40941877]), 'std_score_time': array([0.10486206]), 'param_n_estimators': masked_array(data=[1000],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_max_depth': masked_array(data=[None],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_criterion': masked_array(data=['gini'],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_bootstrap': masked_array(data=[False],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'n_estimators': 1000, 'max_depth': None, 'criterion': 'gini', 'bootstrap': False}], 'split0_test_score': array([0.99147375]), 'split1_test_score': array([0.99162247]), 'split2_test_score': array([0.99097804]), 'split3_test_score': array([0.99152332]), 'split4_test_score': array([0.98949038]), 'mean_test_score': array([0.99101761]), 'std_test_score': array([0.00079543]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([0.99234115]), 'split1_train_score': array([0.99219244]), 'split2_train_score': array([0.99235355]), 'split3_train_score': array([0.99240312]), 'split4_train_score': array([0.99279978]), 'mean_train_score': array([0.99241801]), 'std_train_score': array([0.00020343])}\n",
            "Best Cross-Validated Accuracy: 99.1%\n",
            "Best Model Parameters: {'n_estimators': 1000, 'max_depth': None, 'criterion': 'gini', 'bootstrap': False}\n",
            "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
            "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
            "            oob_score=False, random_state=100, verbose=True,\n",
            "            warm_start=False),\n",
            "          fit_params=None, iid='warn', n_iter=1, n_jobs=None,\n",
            "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000], 'max_depth': [3, None], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']},\n",
            "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
            "          return_train_score='warn', scoring=None, verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 21.5min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aEB0EePDAV5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7296
        },
        "outputId": "c78c625a-0483-41bf-d78c-ce631c56c6e4"
      },
      "source": [
        "# Neural Network Random Search\n",
        "\n",
        "nn_rs = NeuralNetwork(Xtrain, Ytrain, cv=5, n=1) \n",
        "print(nn_rs) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.49712679\n",
            "Iteration 2, loss = 0.39039295\n",
            "Iteration 3, loss = 0.32781217\n",
            "Iteration 4, loss = 0.27524188\n",
            "Iteration 5, loss = 0.23839820\n",
            "Iteration 6, loss = 0.19934226\n",
            "Iteration 7, loss = 0.17487225\n",
            "Iteration 8, loss = 0.14287813\n",
            "Iteration 9, loss = 0.13555724\n",
            "Iteration 10, loss = 0.10471712\n",
            "Iteration 11, loss = 0.09953747\n",
            "Iteration 12, loss = 0.07526548\n",
            "Iteration 13, loss = 0.07082745\n",
            "Iteration 14, loss = 0.06746972\n",
            "Iteration 15, loss = 0.05572004\n",
            "Iteration 16, loss = 0.06781634\n",
            "Iteration 17, loss = 0.04249142\n",
            "Iteration 18, loss = 0.04387244\n",
            "Iteration 19, loss = 0.03883271\n",
            "Iteration 20, loss = 0.05778873\n",
            "Iteration 21, loss = 0.03450006\n",
            "Iteration 22, loss = 0.03725831\n",
            "Iteration 23, loss = 0.03527888\n",
            "Iteration 24, loss = 0.03367426\n",
            "Iteration 25, loss = 0.06326064\n",
            "Iteration 26, loss = 0.02751201\n",
            "Iteration 27, loss = 0.02762235\n",
            "Iteration 28, loss = 0.03468069\n",
            "Iteration 29, loss = 0.03446680\n",
            "Iteration 30, loss = 0.02760830\n",
            "Iteration 31, loss = 0.02527482\n",
            "Iteration 32, loss = 0.02829526\n",
            "Iteration 33, loss = 0.04925037\n",
            "Iteration 34, loss = 0.04080306\n",
            "Iteration 35, loss = 0.02554043\n",
            "Iteration 36, loss = 0.02387993\n",
            "Iteration 37, loss = 0.02460335\n",
            "Iteration 38, loss = 0.02480367\n",
            "Iteration 39, loss = 0.05052078\n",
            "Iteration 40, loss = 0.02342335\n",
            "Iteration 41, loss = 0.04044563\n",
            "Iteration 42, loss = 0.02176701\n",
            "Iteration 43, loss = 0.03358056\n",
            "Iteration 44, loss = 0.02666742\n",
            "Iteration 45, loss = 0.02219228\n",
            "Iteration 46, loss = 0.02303283\n",
            "Iteration 47, loss = 0.02412108\n",
            "Iteration 48, loss = 0.02704033\n",
            "Iteration 49, loss = 0.04970128\n",
            "Iteration 50, loss = 0.02139494\n",
            "Iteration 51, loss = 0.02210090\n",
            "Iteration 52, loss = 0.02307884\n",
            "Iteration 53, loss = 0.03660058\n",
            "Iteration 54, loss = 0.02176215\n",
            "Iteration 55, loss = 0.05846547\n",
            "Iteration 56, loss = 0.02088119\n",
            "Iteration 57, loss = 0.02013358\n",
            "Iteration 58, loss = 0.03040158\n",
            "Iteration 59, loss = 0.02269661\n",
            "Iteration 60, loss = 0.03221134\n",
            "Iteration 61, loss = 0.02864213\n",
            "Iteration 62, loss = 0.02168731\n",
            "Iteration 63, loss = 0.03526489\n",
            "Iteration 64, loss = 0.02171932\n",
            "Iteration 65, loss = 0.02130443\n",
            "Iteration 66, loss = 0.02224200\n",
            "Iteration 67, loss = 0.04489173\n",
            "Iteration 68, loss = 0.02206063\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.49682531\n",
            "Iteration 2, loss = 0.39296775\n",
            "Iteration 3, loss = 0.33072167\n",
            "Iteration 4, loss = 0.28660461\n",
            "Iteration 5, loss = 0.24172099\n",
            "Iteration 6, loss = 0.20433986\n",
            "Iteration 7, loss = 0.17147580\n",
            "Iteration 8, loss = 0.14739944\n",
            "Iteration 9, loss = 0.12473089\n",
            "Iteration 10, loss = 0.11484498\n",
            "Iteration 11, loss = 0.10478602\n",
            "Iteration 12, loss = 0.08186320\n",
            "Iteration 13, loss = 0.07566045\n",
            "Iteration 14, loss = 0.07273694\n",
            "Iteration 15, loss = 0.05502037\n",
            "Iteration 16, loss = 0.05353187\n",
            "Iteration 17, loss = 0.05349071\n",
            "Iteration 18, loss = 0.06343662\n",
            "Iteration 19, loss = 0.05197524\n",
            "Iteration 20, loss = 0.03667217\n",
            "Iteration 21, loss = 0.03687775\n",
            "Iteration 22, loss = 0.03292617\n",
            "Iteration 23, loss = 0.07443312\n",
            "Iteration 24, loss = 0.03047890\n",
            "Iteration 25, loss = 0.03039429\n",
            "Iteration 26, loss = 0.03909463\n",
            "Iteration 27, loss = 0.02931807\n",
            "Iteration 28, loss = 0.02779311\n",
            "Iteration 29, loss = 0.05884011\n",
            "Iteration 30, loss = 0.03270802\n",
            "Iteration 31, loss = 0.02499972\n",
            "Iteration 32, loss = 0.02691867\n",
            "Iteration 33, loss = 0.02791530\n",
            "Iteration 34, loss = 0.03891439\n",
            "Iteration 35, loss = 0.04162467\n",
            "Iteration 36, loss = 0.03657026\n",
            "Iteration 37, loss = 0.02339866\n",
            "Iteration 38, loss = 0.02437363\n",
            "Iteration 39, loss = 0.02470069\n",
            "Iteration 40, loss = 0.03103702\n",
            "Iteration 41, loss = 0.03185426\n",
            "Iteration 42, loss = 0.02591443\n",
            "Iteration 43, loss = 0.03335199\n",
            "Iteration 44, loss = 0.02280932\n",
            "Iteration 45, loss = 0.03638444\n",
            "Iteration 46, loss = 0.02060618\n",
            "Iteration 47, loss = 0.03515311\n",
            "Iteration 48, loss = 0.03438586\n",
            "Iteration 49, loss = 0.02305295\n",
            "Iteration 50, loss = 0.02114344\n",
            "Iteration 51, loss = 0.02526011\n",
            "Iteration 52, loss = 0.03716599\n",
            "Iteration 53, loss = 0.02289975\n",
            "Iteration 54, loss = 0.02457008\n",
            "Iteration 55, loss = 0.02113916\n",
            "Iteration 56, loss = 0.03269078\n",
            "Iteration 57, loss = 0.02092922\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.49667083\n",
            "Iteration 2, loss = 0.39246979\n",
            "Iteration 3, loss = 0.33177205\n",
            "Iteration 4, loss = 0.28216462\n",
            "Iteration 5, loss = 0.23447033\n",
            "Iteration 6, loss = 0.20413925\n",
            "Iteration 7, loss = 0.17085770\n",
            "Iteration 8, loss = 0.15104257\n",
            "Iteration 9, loss = 0.12316829\n",
            "Iteration 10, loss = 0.10707082\n",
            "Iteration 11, loss = 0.10075893\n",
            "Iteration 12, loss = 0.08064399\n",
            "Iteration 13, loss = 0.07901257\n",
            "Iteration 14, loss = 0.06321565\n",
            "Iteration 15, loss = 0.06237403\n",
            "Iteration 16, loss = 0.05481002\n",
            "Iteration 17, loss = 0.07567824\n",
            "Iteration 18, loss = 0.04550764\n",
            "Iteration 19, loss = 0.03976372\n",
            "Iteration 20, loss = 0.03726702\n",
            "Iteration 21, loss = 0.04708659\n",
            "Iteration 22, loss = 0.03395553\n",
            "Iteration 23, loss = 0.06466919\n",
            "Iteration 24, loss = 0.02998417\n",
            "Iteration 25, loss = 0.03181160\n",
            "Iteration 26, loss = 0.03975139\n",
            "Iteration 27, loss = 0.03860830\n",
            "Iteration 28, loss = 0.03245239\n",
            "Iteration 29, loss = 0.03567800\n",
            "Iteration 30, loss = 0.02583289\n",
            "Iteration 31, loss = 0.02580796\n",
            "Iteration 32, loss = 0.05013566\n",
            "Iteration 33, loss = 0.02889390\n",
            "Iteration 34, loss = 0.03601634\n",
            "Iteration 35, loss = 0.02597458\n",
            "Iteration 36, loss = 0.03375365\n",
            "Iteration 37, loss = 0.02824960\n",
            "Iteration 38, loss = 0.03121077\n",
            "Iteration 39, loss = 0.02375081\n",
            "Iteration 40, loss = 0.05022473\n",
            "Iteration 41, loss = 0.02292983\n",
            "Iteration 42, loss = 0.02256959\n",
            "Iteration 43, loss = 0.03741400\n",
            "Iteration 44, loss = 0.02250210\n",
            "Iteration 45, loss = 0.02266983\n",
            "Iteration 46, loss = 0.02838516\n",
            "Iteration 47, loss = 0.02640147\n",
            "Iteration 48, loss = 0.02300225\n",
            "Iteration 49, loss = 0.06089398\n",
            "Iteration 50, loss = 0.02072966\n",
            "Iteration 51, loss = 0.02909924\n",
            "Iteration 52, loss = 0.02324879\n",
            "Iteration 53, loss = 0.02647971\n",
            "Iteration 54, loss = 0.02890251\n",
            "Iteration 55, loss = 0.02792849\n",
            "Iteration 56, loss = 0.02421232\n",
            "Iteration 57, loss = 0.03093978\n",
            "Iteration 58, loss = 0.02386763\n",
            "Iteration 59, loss = 0.02790812\n",
            "Iteration 60, loss = 0.02484125\n",
            "Iteration 61, loss = 0.04379603\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.49853039\n",
            "Iteration 2, loss = 0.39856694\n",
            "Iteration 3, loss = 0.34410713\n",
            "Iteration 4, loss = 0.29197765\n",
            "Iteration 5, loss = 0.25031349\n",
            "Iteration 6, loss = 0.21417221\n",
            "Iteration 7, loss = 0.17985782\n",
            "Iteration 8, loss = 0.15761685\n",
            "Iteration 9, loss = 0.12834610\n",
            "Iteration 10, loss = 0.11332851\n",
            "Iteration 11, loss = 0.09656212\n",
            "Iteration 12, loss = 0.09115647\n",
            "Iteration 13, loss = 0.07344272\n",
            "Iteration 14, loss = 0.06080271\n",
            "Iteration 15, loss = 0.06275510\n",
            "Iteration 16, loss = 0.05472559\n",
            "Iteration 17, loss = 0.07520136\n",
            "Iteration 18, loss = 0.04272134\n",
            "Iteration 19, loss = 0.04030266\n",
            "Iteration 20, loss = 0.03600127\n",
            "Iteration 21, loss = 0.05518143\n",
            "Iteration 22, loss = 0.04207817\n",
            "Iteration 23, loss = 0.03041970\n",
            "Iteration 24, loss = 0.04198187\n",
            "Iteration 25, loss = 0.03516272\n",
            "Iteration 26, loss = 0.02922947\n",
            "Iteration 27, loss = 0.06234606\n",
            "Iteration 28, loss = 0.03091946\n",
            "Iteration 29, loss = 0.02537379\n",
            "Iteration 30, loss = 0.02518539\n",
            "Iteration 31, loss = 0.04301420\n",
            "Iteration 32, loss = 0.03470449\n",
            "Iteration 33, loss = 0.03114573\n",
            "Iteration 34, loss = 0.02570388\n",
            "Iteration 35, loss = 0.03405278\n",
            "Iteration 36, loss = 0.02710150\n",
            "Iteration 37, loss = 0.02423594\n",
            "Iteration 38, loss = 0.02463780\n",
            "Iteration 39, loss = 0.03278420\n",
            "Iteration 40, loss = 0.04605140\n",
            "Iteration 41, loss = 0.02309599\n",
            "Iteration 42, loss = 0.02162115\n",
            "Iteration 43, loss = 0.02972418\n",
            "Iteration 44, loss = 0.03698561\n",
            "Iteration 45, loss = 0.02150208\n",
            "Iteration 46, loss = 0.03286402\n",
            "Iteration 47, loss = 0.02163560\n",
            "Iteration 48, loss = 0.02328167\n",
            "Iteration 49, loss = 0.02152695\n",
            "Iteration 50, loss = 0.02236164\n",
            "Iteration 51, loss = 0.03543194\n",
            "Iteration 52, loss = 0.03817299\n",
            "Iteration 53, loss = 0.02118598\n",
            "Iteration 54, loss = 0.02144774\n",
            "Iteration 55, loss = 0.02706972\n",
            "Iteration 56, loss = 0.02965203\n",
            "Iteration 57, loss = 0.02741429\n",
            "Iteration 58, loss = 0.04601827\n",
            "Iteration 59, loss = 0.02002522\n",
            "Iteration 60, loss = 0.02076787\n",
            "Iteration 61, loss = 0.03099350\n",
            "Iteration 62, loss = 0.02101263\n",
            "Iteration 63, loss = 0.02125316\n",
            "Iteration 64, loss = 0.03184694\n",
            "Iteration 65, loss = 0.02040511\n",
            "Iteration 66, loss = 0.02873768\n",
            "Iteration 67, loss = 0.03224286\n",
            "Iteration 68, loss = 0.01970777\n",
            "Iteration 69, loss = 0.02241620\n",
            "Iteration 70, loss = 0.02054867\n",
            "Iteration 71, loss = 0.03605899\n",
            "Iteration 72, loss = 0.02079386\n",
            "Iteration 73, loss = 0.02369918\n",
            "Iteration 74, loss = 0.02092848\n",
            "Iteration 75, loss = 0.03758562\n",
            "Iteration 76, loss = 0.01952557\n",
            "Iteration 77, loss = 0.02049848\n",
            "Iteration 78, loss = 0.02513806\n",
            "Iteration 79, loss = 0.02081774\n",
            "Iteration 80, loss = 0.04548456\n",
            "Iteration 81, loss = 0.02001542\n",
            "Iteration 82, loss = 0.01953634\n",
            "Iteration 83, loss = 0.02107104\n",
            "Iteration 84, loss = 0.03205108\n",
            "Iteration 85, loss = 0.02076558\n",
            "Iteration 86, loss = 0.02256467\n",
            "Iteration 87, loss = 0.03368319\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.49603448\n",
            "Iteration 2, loss = 0.39011481\n",
            "Iteration 3, loss = 0.33119213\n",
            "Iteration 4, loss = 0.27931489\n",
            "Iteration 5, loss = 0.23730317\n",
            "Iteration 6, loss = 0.19862573\n",
            "Iteration 7, loss = 0.18154795\n",
            "Iteration 8, loss = 0.14646287\n",
            "Iteration 9, loss = 0.13035208\n",
            "Iteration 10, loss = 0.10576199\n",
            "Iteration 11, loss = 0.10593488\n",
            "Iteration 12, loss = 0.08665749\n",
            "Iteration 13, loss = 0.08344908\n",
            "Iteration 14, loss = 0.06656012\n",
            "Iteration 15, loss = 0.06726667\n",
            "Iteration 16, loss = 0.05134812\n",
            "Iteration 17, loss = 0.04849161\n",
            "Iteration 18, loss = 0.05004364\n",
            "Iteration 19, loss = 0.07714529\n",
            "Iteration 20, loss = 0.03661967\n",
            "Iteration 21, loss = 0.05778191\n",
            "Iteration 22, loss = 0.03388459\n",
            "Iteration 23, loss = 0.03643259\n",
            "Iteration 24, loss = 0.03545431\n",
            "Iteration 25, loss = 0.05487092\n",
            "Iteration 26, loss = 0.03155631\n",
            "Iteration 27, loss = 0.03647591\n",
            "Iteration 28, loss = 0.02757706\n",
            "Iteration 29, loss = 0.04870348\n",
            "Iteration 30, loss = 0.02764449\n",
            "Iteration 31, loss = 0.03553564\n",
            "Iteration 32, loss = 0.03975369\n",
            "Iteration 33, loss = 0.02508757\n",
            "Iteration 34, loss = 0.03954751\n",
            "Iteration 35, loss = 0.03017259\n",
            "Iteration 36, loss = 0.02390845\n",
            "Iteration 37, loss = 0.04267282\n",
            "Iteration 38, loss = 0.02543045\n",
            "Iteration 39, loss = 0.03574626\n",
            "Iteration 40, loss = 0.03241257\n",
            "Iteration 41, loss = 0.03559628\n",
            "Iteration 42, loss = 0.02665079\n",
            "Iteration 43, loss = 0.02234128\n",
            "Iteration 44, loss = 0.02211203\n",
            "Iteration 45, loss = 0.03277873\n",
            "Iteration 46, loss = 0.02285927\n",
            "Iteration 47, loss = 0.03000964\n",
            "Iteration 48, loss = 0.03032465\n",
            "Iteration 49, loss = 0.02849101\n",
            "Iteration 50, loss = 0.02333522\n",
            "Iteration 51, loss = 0.03616955\n",
            "Iteration 52, loss = 0.04561176\n",
            "Iteration 53, loss = 0.02028489\n",
            "Iteration 54, loss = 0.02522442\n",
            "Iteration 55, loss = 0.03654452\n",
            "Iteration 56, loss = 0.02151518\n",
            "Iteration 57, loss = 0.02196657\n",
            "Iteration 58, loss = 0.02693241\n",
            "Iteration 59, loss = 0.02514209\n",
            "Iteration 60, loss = 0.03545652\n",
            "Iteration 61, loss = 0.02316903\n",
            "Iteration 62, loss = 0.02621852\n",
            "Iteration 63, loss = 0.02625665\n",
            "Iteration 64, loss = 0.02287280\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.48144625\n",
            "Iteration 2, loss = 0.37331965\n",
            "Iteration 3, loss = 0.30856564\n",
            "Iteration 4, loss = 0.25583414\n",
            "Iteration 5, loss = 0.20786279\n",
            "Iteration 6, loss = 0.17155997\n",
            "Iteration 7, loss = 0.14422842\n",
            "Iteration 8, loss = 0.11835145\n",
            "Iteration 9, loss = 0.09464410\n",
            "Iteration 10, loss = 0.08415359\n",
            "Iteration 11, loss = 0.07258024\n",
            "Iteration 12, loss = 0.06692895\n",
            "Iteration 13, loss = 0.05544264\n",
            "Iteration 14, loss = 0.06571787\n",
            "Iteration 15, loss = 0.04393701\n",
            "Iteration 16, loss = 0.03769421\n",
            "Iteration 17, loss = 0.06033620\n",
            "Iteration 18, loss = 0.03329119\n",
            "Iteration 19, loss = 0.05361480\n",
            "Iteration 20, loss = 0.03056959\n",
            "Iteration 21, loss = 0.03982150\n",
            "Iteration 22, loss = 0.04058753\n",
            "Iteration 23, loss = 0.03894079\n",
            "Iteration 24, loss = 0.02773865\n",
            "Iteration 25, loss = 0.03131260\n",
            "Iteration 26, loss = 0.05342488\n",
            "Iteration 27, loss = 0.02803843\n",
            "Iteration 28, loss = 0.02714644\n",
            "Iteration 29, loss = 0.03387485\n",
            "Iteration 30, loss = 0.02292211\n",
            "Iteration 31, loss = 0.03474808\n",
            "Iteration 32, loss = 0.02423527\n",
            "Iteration 33, loss = 0.02541714\n",
            "Iteration 34, loss = 0.03652957\n",
            "Iteration 35, loss = 0.02214636\n",
            "Iteration 36, loss = 0.04186122\n",
            "Iteration 37, loss = 0.02496635\n",
            "Iteration 38, loss = 0.05077544\n",
            "Iteration 39, loss = 0.02960303\n",
            "Iteration 40, loss = 0.02116159\n",
            "Iteration 41, loss = 0.02576115\n",
            "Iteration 42, loss = 0.03048370\n",
            "Iteration 43, loss = 0.02864194\n",
            "Iteration 44, loss = 0.03000165\n",
            "Iteration 45, loss = 0.02250596\n",
            "Iteration 46, loss = 0.02931935\n",
            "Iteration 47, loss = 0.02287354\n",
            "Iteration 48, loss = 0.05314936\n",
            "Iteration 49, loss = 0.02259440\n",
            "Iteration 50, loss = 0.02240632\n",
            "Iteration 51, loss = 0.02421491\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "{'mean_fit_time': array([113.78084426]), 'std_fit_time': array([17.2773084]), 'mean_score_time': array([0.12577901]), 'std_score_time': array([0.02649215]), 'param_solver': masked_array(data=['adam'],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_shuffle': masked_array(data=[True],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_learning_rate': masked_array(data=['adaptive'],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_hidden_layer_sizes': masked_array(data=[(100,)],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_alpha': masked_array(data=[0.0001],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_activation': masked_array(data=['relu'],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'solver': 'adam', 'shuffle': True, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100,), 'alpha': 0.0001, 'activation': 'relu'}], 'split0_test_score': array([0.99231646]), 'split1_test_score': array([0.99231646]), 'split2_test_score': array([0.98830119]), 'split3_test_score': array([0.99177118]), 'split4_test_score': array([0.99033314]), 'mean_test_score': array([0.99100769]), 'std_test_score': array([0.00153551]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([0.99187022]), 'split1_train_score': array([0.99191979]), 'split2_train_score': array([0.98932967]), 'split3_train_score': array([0.99204372]), 'split4_train_score': array([0.99252714]), 'mean_train_score': array([0.99153811]), 'std_train_score': array([0.00112845])}\n",
            "Best Cross-Validated Accuracy: 99.1%\n",
            "Best Model Parameters: {'solver': 'adam', 'shuffle': True, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100,), 'alpha': 0.0001, 'activation': 'relu'}\n",
            "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
            "          estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
            "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
            "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
            "       random_state=100, shuffle=True, solver='adam', tol=0.0001,\n",
            "       validation_fraction=0.1, verbose=True, warm_start=False),\n",
            "          fit_params=None, iid='warn', n_iter=1, n_jobs=None,\n",
            "          param_distributions={'hidden_layer_sizes': [(100,), (150,), (200,), (250,), (300,)], 'activation': ['logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'alpha': [0.0001, 1e-08, 1e-12, 1e-18], 'learning_rate': ['constant', 'adaptive'], 'shuffle': [True, False]},\n",
            "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
            "          return_train_score='warn', scoring=None, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roll-9-5DRkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f80fee61-47cb-483b-d144-6a6d086cb49f"
      },
      "source": [
        "# Logistic Regression Random Search \n",
        "\n",
        "lr_rs = noSGDLogisticRegression(Xtrain, Ytrain, cv=5, n=1) \n",
        "print(lr_rs) "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]{'mean_fit_time': array([81.02607403]), 'std_fit_time': array([20.63617664]), 'mean_score_time': array([0.01470532]), 'std_score_time': array([0.00407968]), 'param_penalty': masked_array(data=['l2'],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_intercept_scaling': masked_array(data=[1.25],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_fit_intercept': masked_array(data=[True],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'penalty': 'l2', 'intercept_scaling': 1.25, 'fit_intercept': True}], 'split0_test_score': array([0.81797452]), 'split1_test_score': array([0.81916423]), 'split2_test_score': array([0.82223764]), 'split3_test_score': array([0.82595549]), 'split4_test_score': array([0.81865953]), 'mean_test_score': array([0.8207983]), 'std_test_score': array([0.00296266]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([0.82397046]), 'split1_train_score': array([0.82188844]), 'split2_train_score': array([0.82099615]), 'split3_train_score': array([0.82204955]), 'split4_train_score': array([0.82104794]), 'mean_train_score': array([0.8219905]), 'std_train_score': array([0.00107808])}\n",
            "Best Cross-Validated Accuracy: 82.08%\n",
            "Best Model Parameters: {'penalty': 'l2', 'intercept_scaling': 1.25, 'fit_intercept': True}\n",
            "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
            "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=100, solver='warn',\n",
            "          tol=0.0001, verbose=True, warm_start=False),\n",
            "          fit_params=None, iid='warn', n_iter=1, n_jobs=None,\n",
            "          param_distributions={'penalty': ['l1', 'l2'], 'fit_intercept': [False, True], 'intercept_scaling': [1, 1.25, 1.5, 1.75, 2]},\n",
            "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
            "          return_train_score='warn', scoring=None, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}